+++
title= "如果互联网有记忆"
date = "2020-02-28T15:22:49+08:00"
description = "Memory"
keywords = ["Life"]
categories = ["Life"]
+++
下午在家里等编译完成，忽然想看看有没有工具可以将微博上的文章都批量抓取下来，一搜，果然有：    

[https://github.com/dataabc/weiboSpider](https://github.com/dataabc/weiboSpider)    

简单的配置以后开始了漫长的下载过程，    

![/images/2020_02_28_15_24_29_774x758.jpg](/images/2020_02_28_15_24_29_774x758.jpg)

分页后大概有1400多页，估计有半个小时就能生成归档。    

微博近些年来被阉割得不行了，什么都不能说，偶尔看到的一点稍微敏感点的东西马上就无法访问。照此下去，没准哪一天它就突然被全网关停我一定都不会奇怪。我的微博账户早年因为寿光大水的话题多说了两句话已经被封。所以想用工具将以前说过的东西都保留下来。很多当时说过的话、转过的话题、有过的情绪，再看起来也只能嗟叹了。尽管如此，记忆还是应该被保留下来的。年老的时候偶尔翻起，会重温起年轻时的golden old days.    

多么抓狂天真而幼稚的文字啊，也不亏我好好度完了这一生----那时候的我一定会这么想吧。
